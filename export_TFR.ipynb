{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d193ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pywt\n",
    "from openmovement.load import CwaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9efda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cwa(filename):\n",
    "    with CwaData(filename, include_gyro=True, include_temperature=False) as cwa_data:\n",
    "        samples = cwa_data.get_samples()\n",
    "        samples = samples.set_index('time')\n",
    "        samples = samples.astype('float32')\n",
    "        samples = samples.resample('500ms').sum() # Sub-sampled data\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff74da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(X,w_l=64):\n",
    "    X = np.transpose(X) \n",
    "    nt, nf = X.shape\n",
    "    nb = 2*nt//w_l-1\n",
    "    X_w = np.zeros((nb,w_l,nf),dtype=np.float32)\n",
    "    for k in range(nb):\n",
    "        X_w[k,:,:] = X[k*(w_l//2):(k+1)*(w_l//2)+(w_l//2),:]\n",
    "    return np.expand_dims(X_w, axis=-1) # shape: (nb,w_l,nf,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5e07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_dataset, pat_file_names):#, tf_writer):\n",
    "    \"\"\"\n",
    "    Load data and creates a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    dir_dataset: directory of dataset files.\n",
    "\n",
    "    Returns:\n",
    "    Dictionary containing all files.\n",
    "\n",
    "    \"\"\"\n",
    "    ini_flag = False\n",
    "    for p in pat_file_names:\n",
    "        print('Patient No.',p)\n",
    "        for cwa_f in os.listdir(os.path.join(dir_dataset, p, 'IMU')):\n",
    "            print('  Analyzing file',cwa_f)\n",
    "            cwt_flag = False\n",
    "            id_num = cwa_f.split('_')[1]\n",
    "            file_name = os.path.join(dir_dataset, p, 'IMU', cwa_f)\n",
    "            df = load_cwa(file_name)\n",
    "            sensor_idxs = list(df.keys())\n",
    "            for sens_idx in sensor_idxs:\n",
    "                print('    Data from sensor',sens_idx)\n",
    "                if sens_idx.split('_')[0] == 'gyro':\n",
    "                    scales = np.arange(1,641,10)\n",
    "                else:\n",
    "                    scales = np.arange(1,1025,16)\n",
    "                # apply  PyWavelets continuous wavelet transfromation function\n",
    "                coeffs, freqs = pywt.cwt(df[sens_idx], scales, wavelet = 'mexh')\n",
    "                coeffs_w = window_data(coeffs)\n",
    "                if not(cwt_flag):\n",
    "                    X_file = coeffs_w\n",
    "                    cwt_flag = True\n",
    "                else:\n",
    "                    X_file = np.concatenate((X_file,coeffs_w),axis=-1)\n",
    "            if not(ini_flag):\n",
    "                X = X_file\n",
    "                y = [cwa_f.split('.')[0] for _ in range(X_file.shape[0])]\n",
    "                ini_flag = True\n",
    "            else:\n",
    "                X = np.concatenate((X,X_file), axis=0)\n",
    "                y += [cwa_f.split('.')[0] for _ in range(X_file.shape[0])]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf59d78",
   "metadata": {},
   "source": [
    "## Create TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53520b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c5551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient No. 03\n",
      "  Analyzing file 00_506_1.CWA\n",
      "    Data from sensor accel_x\n",
      "    Data from sensor accel_y\n",
      "    Data from sensor accel_z\n",
      "    Data from sensor gyro_x\n",
      "    Data from sensor gyro_y\n",
      "    Data from sensor gyro_z\n",
      "Patient No. 14\n",
      "  Analyzing file 01_543_3.CWA\n",
      "    Data from sensor accel_x\n",
      "    Data from sensor accel_y\n",
      "    Data from sensor accel_z\n",
      "    Data from sensor gyro_x\n",
      "    Data from sensor gyro_y\n",
      "    Data from sensor gyro_z\n"
     ]
    }
   ],
   "source": [
    "file_dir = '../Data/'\n",
    "pat_filenames = ['03','14']\n",
    "\n",
    "recordPath = \"tfrecord/\"\n",
    "# writer = tf.io.TFRecordWriter(recordPath + 'TFR-IMUdata')\n",
    "\n",
    "X,y = load_data(file_dir, pat_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06701534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67568, 64, 64, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d08eae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67568"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f625ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    for file_name in os.listdir(subj_path):\n",
    "        if '2D_' in file_name:\n",
    "            print('\\t' + 'Processing ' + file_name)\n",
    "            img_path = os.path.join(subj_path, file_name)\n",
    "            img_path = os.path.join(img_path, os.listdir(img_path)[0])\n",
    "            img_mat = sio.loadmat(img_path)\n",
    "            acq = img_mat['imDataParams'][0,0][0].astype('complex64')\n",
    "            TE = img_mat['imDataParams'][0,0][1].astype('float32')\n",
    "            acq_real = np.real(acq)\n",
    "            acq_imag = np.imag(acq)\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'acq_real': _float_feature(acq_real.flatten()),\n",
    "                'acq_imag': _float_feature(acq_imag.flatten()),\n",
    "                'te': _float_feature(TE.flatten()),\n",
    "                'height': _int64_feature(acq.shape[0]),\n",
    "                'width': _int64_feature(acq.shape[1]),\n",
    "                'num_slices': _int64_feature(acq.shape[2]),\n",
    "                'num_echoes': _int64_feature(acq.shape[4])}))\n",
    "            writer.write(example.SerializeToString())\n",
    "        if 'results_' in file_name:\n",
    "            print('\\t' + 'Processing ' + file_name)\n",
    "            out_path = os.path.join(subj_path, file_name)\n",
    "            out_path = os.path.join(out_path, os.listdir(out_path)[0])\n",
    "            out_mat = sio.loadmat(out_path)\n",
    "            wf = out_mat['R'].astype('complex64')\n",
    "            wf_real = np.real(wf)\n",
    "            wf_imag = np.imag(wf)\n",
    "            r2 = out_mat['R2'].astype('float32')\n",
    "            fm = out_mat['P'].astype('float32')\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                \"wf_real\": _float_feature(wf_real.flatten()),\n",
    "                \"wf_imag\": _float_feature(wf_imag.flatten()),\n",
    "                \"r2\": _float_feature(r2.flatten()),\n",
    "                \"fm\": _float_feature(fm.flatten()),\n",
    "                'height': _int64_feature(wf.shape[0]),\n",
    "                'width': _int64_feature(wf.shape[1]),\n",
    "                'num_slices': _int64_feature(wf.shape[2]),\n",
    "                'num_specie': _int64_feature(wf.shape[3])}))\n",
    "            writer.write(example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34771e4e",
   "metadata": {},
   "source": [
    "## Load images from TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad46c5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'asda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes('asda','utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
